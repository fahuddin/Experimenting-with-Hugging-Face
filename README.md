# Hugging Face Practice & Experiments

This repository documents my **practice and experimentation with Hugging Face**, focusing on building hands-on experience with modern NLP tools and workflows.

## Goals
- Explore the **Transformers library** and Hugging Face ecosystem  
- Learn how to **load and run pre-trained models**  
- Experiment with **pipelines** (sentiment analysis, text classification, question answering, etc.)  
- Understand **tokenization and embeddings**  
- Practice **fine-tuning models** on custom datasets  
- Learn how to **save, share, and deploy models** using the Hugging Face Hub  

## Why This Repo Exists
This project is **not production-ready code** — it’s meant to:
- Serve as a **learning journal** of my progress  
- Provide **working examples** I can revisit later  


## Experiments So Far
- ✅ Running a sentiment analysis pipeline  
- ✅ Extracting embeddings from BERT-based models  
- ⏳ Fine-tuning a small classification model (in progress)  
- ⏳ Exploring tokenizers and dataset preprocessing  

## Next Steps
- Fine-tune a Transformer on a custom dataset  
- Explore Hugging Face’s integration with PyTorch and TensorFlow  
- Push a trained model to the Hugging Face Hub  
- Experiment with model evaluation and explainability tools  

---
